{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-1RUl0SXy4K"
      },
      "source": [
        "Vaibhav Uniyal\n",
        "\n",
        "22070126126\n",
        "\n",
        "AIML B2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gE7rmebJX4Cb",
        "outputId": "757cbcae-6fa1-4569-c996-9268bc672416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.2.18)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision medmnist tensorboard scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxcJp16hXhlv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.inception import inception_v3\n",
        "from medmnist import PathMNIST\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from scipy.linalg import sqrtm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asl1YP3pXlUc"
      },
      "outputs": [],
      "source": [
        "# Initialize TensorBoard\n",
        "writer = SummaryWriter(\"runs/GAN_MedMNIST\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-55v503Xqtt"
      },
      "outputs": [],
      "source": [
        "# Set Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iitwzeg6ZEQc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Manually creating the dataset directory\n",
        "os.makedirs(\"/content/data\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET8h-bfQaJ3w"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"generated\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVHN-c8lXs9f",
        "outputId": "7200d1e0-4e21-4c56-cd88-8b64bf01a531"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 206M/206M [04:57<00:00, 692kB/s]\n"
          ]
        }
      ],
      "source": [
        "from medmnist import PathMNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the Dataset\n",
        "dataset = PathMNIST(root=\"/content/data\", split=\"train\", transform=transform, download=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFGbGoV75zHY"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe5w2RibXvrD"
      },
      "outputs": [],
      "source": [
        "# Define Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img.view(img.size(0), 1, 28, 28)\n",
        "\n",
        "# Define Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        return self.model(img_flat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ-6URhiYKEE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Wasserstein GAN with Gradient Penalty\n",
        "def compute_gradient_penalty(D, real_samples, fake_samples, device=None):\n",
        "    if device is None:\n",
        "        device = real_samples.device  # Infer device from input tensor\n",
        "\n",
        "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n",
        "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
        "\n",
        "    d_interpolates = D(interpolates)\n",
        "\n",
        "    fake = torch.ones_like(d_interpolates, device=device)\n",
        "\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0]\n",
        "\n",
        "    if gradients is None:\n",
        "        raise RuntimeError(\"Gradients are None. Ensure D(interpolates) requires gradients.\")\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "\n",
        "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wdDdewpYQbn"
      },
      "outputs": [],
      "source": [
        "# Training Function\n",
        "def train_gan(gan_type=\"LSGAN\", epochs=50):\n",
        "    generator = Generator().to(device)\n",
        "    discriminator = Discriminator().to(device)\n",
        "\n",
        "    if gan_type == \"LSGAN\":\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    elif gan_type == \"WGAN\":\n",
        "        optimizer_G = optim.RMSprop(generator.parameters(), lr=0.00005)\n",
        "        optimizer_D = optim.RMSprop(discriminator.parameters(), lr=0.00005)\n",
        "\n",
        "    elif gan_type == \"WGAN-GP\":\n",
        "        optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
        "        optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (real_imgs, _) in enumerate(dataloader):\n",
        "            real_imgs = real_imgs.to(device)\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            z = torch.randn(real_imgs.size(0), 100, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            real_validity = discriminator(real_imgs)\n",
        "            fake_validity = discriminator(fake_imgs.detach())\n",
        "\n",
        "            if gan_type == \"LSGAN\":\n",
        "                real_loss = criterion(real_validity, torch.ones_like(real_validity))\n",
        "                fake_loss = criterion(fake_validity, torch.zeros_like(fake_validity))\n",
        "                d_loss = (real_loss + fake_loss) / 2\n",
        "            elif gan_type == \"WGAN\":\n",
        "                d_loss = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
        "                for p in discriminator.parameters():\n",
        "                    p.data.clamp_(-0.01, 0.01)\n",
        "            elif gan_type == \"WGAN-GP\":\n",
        "                gradient_penalty = compute_gradient_penalty(discriminator, real_imgs, fake_imgs)\n",
        "                d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + 10 * gradient_penalty\n",
        "\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "            if i % 5 == 0:\n",
        "                optimizer_G.zero_grad()\n",
        "                fake_validity = discriminator(fake_imgs)\n",
        "                g_loss = -torch.mean(fake_validity) if gan_type != \"LSGAN\" else criterion(fake_validity, torch.ones_like(fake_validity))\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "        writer.add_scalar(f\"{gan_type}/D_Loss\", d_loss.item(), epoch)\n",
        "        writer.add_scalar(f\"{gan_type}/G_Loss\", g_loss.item(), epoch)\n",
        "\n",
        "        print(f\"[{gan_type}] Epoch {epoch+1}/{epochs} - D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            vutils.save_image(fake_imgs[:25], f\"generated/{gan_type}_epoch_{epoch}.png\", normalize=True)\n",
        "\n",
        "    torch.save(generator.state_dict(), f\"{gan_type}_generator.pth\")\n",
        "    print(f\"{gan_type} Training Complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgkVuX0uaF1T",
        "outputId": "6db385c8-333a-48bb-a7f6-084cb140824e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🚀 Training LSGAN...\n",
            "[LSGAN] Epoch 1/50 - D Loss: 0.1124, G Loss: 0.5152\n",
            "[LSGAN] Epoch 2/50 - D Loss: 0.1429, G Loss: 0.8137\n",
            "[LSGAN] Epoch 3/50 - D Loss: 0.0854, G Loss: 0.5972\n",
            "[LSGAN] Epoch 4/50 - D Loss: 0.1222, G Loss: 0.7807\n",
            "[LSGAN] Epoch 5/50 - D Loss: 0.1063, G Loss: 0.5290\n",
            "[LSGAN] Epoch 6/50 - D Loss: 0.0928, G Loss: 0.5823\n",
            "[LSGAN] Epoch 7/50 - D Loss: 0.1285, G Loss: 0.7184\n",
            "[LSGAN] Epoch 8/50 - D Loss: 0.1102, G Loss: 0.7259\n",
            "[LSGAN] Epoch 9/50 - D Loss: 0.1575, G Loss: 0.5468\n",
            "[LSGAN] Epoch 10/50 - D Loss: 0.2292, G Loss: 0.4668\n",
            "[LSGAN] Epoch 11/50 - D Loss: 0.1385, G Loss: 0.6293\n",
            "[LSGAN] Epoch 12/50 - D Loss: 0.2288, G Loss: 0.5887\n",
            "[LSGAN] Epoch 13/50 - D Loss: 0.1752, G Loss: 0.4263\n",
            "[LSGAN] Epoch 14/50 - D Loss: 0.2065, G Loss: 0.3495\n",
            "[LSGAN] Epoch 15/50 - D Loss: 0.1539, G Loss: 0.6565\n",
            "[LSGAN] Epoch 16/50 - D Loss: 0.1401, G Loss: 0.4946\n",
            "[LSGAN] Epoch 17/50 - D Loss: 0.1163, G Loss: 0.6041\n",
            "[LSGAN] Epoch 18/50 - D Loss: 0.1436, G Loss: 0.5261\n",
            "[LSGAN] Epoch 19/50 - D Loss: 0.1933, G Loss: 0.4578\n",
            "[LSGAN] Epoch 20/50 - D Loss: 0.1454, G Loss: 0.6990\n",
            "[LSGAN] Epoch 21/50 - D Loss: 0.1778, G Loss: 0.5318\n",
            "[LSGAN] Epoch 22/50 - D Loss: 0.1391, G Loss: 0.7937\n",
            "[LSGAN] Epoch 23/50 - D Loss: 0.1373, G Loss: 0.6429\n",
            "[LSGAN] Epoch 24/50 - D Loss: 0.1425, G Loss: 0.5897\n",
            "[LSGAN] Epoch 25/50 - D Loss: 0.2542, G Loss: 0.2505\n",
            "[LSGAN] Epoch 26/50 - D Loss: 0.1458, G Loss: 0.5604\n",
            "[LSGAN] Epoch 27/50 - D Loss: 0.1147, G Loss: 0.6150\n",
            "[LSGAN] Epoch 28/50 - D Loss: 0.1656, G Loss: 0.6586\n",
            "[LSGAN] Epoch 29/50 - D Loss: 0.3649, G Loss: 0.3402\n",
            "[LSGAN] Epoch 30/50 - D Loss: 0.1497, G Loss: 0.8224\n",
            "[LSGAN] Epoch 31/50 - D Loss: 0.0816, G Loss: 0.5802\n",
            "[LSGAN] Epoch 32/50 - D Loss: 0.1295, G Loss: 0.5847\n",
            "[LSGAN] Epoch 33/50 - D Loss: 0.1688, G Loss: 0.4737\n",
            "[LSGAN] Epoch 34/50 - D Loss: 0.1472, G Loss: 0.5856\n",
            "[LSGAN] Epoch 35/50 - D Loss: 0.1895, G Loss: 0.5000\n",
            "[LSGAN] Epoch 36/50 - D Loss: 0.1849, G Loss: 0.4727\n",
            "[LSGAN] Epoch 37/50 - D Loss: 0.2366, G Loss: 0.4573\n",
            "[LSGAN] Epoch 38/50 - D Loss: 0.2192, G Loss: 0.5300\n",
            "[LSGAN] Epoch 39/50 - D Loss: 0.1745, G Loss: 0.6268\n",
            "[LSGAN] Epoch 40/50 - D Loss: 0.1591, G Loss: 0.8088\n",
            "[LSGAN] Epoch 41/50 - D Loss: 0.1783, G Loss: 0.7698\n",
            "[LSGAN] Epoch 42/50 - D Loss: 0.2732, G Loss: 0.2849\n",
            "[LSGAN] Epoch 43/50 - D Loss: 0.1780, G Loss: 0.5614\n",
            "[LSGAN] Epoch 44/50 - D Loss: 0.1286, G Loss: 0.5372\n",
            "[LSGAN] Epoch 45/50 - D Loss: 0.1925, G Loss: 0.4674\n",
            "[LSGAN] Epoch 46/50 - D Loss: 0.1928, G Loss: 0.4808\n",
            "[LSGAN] Epoch 47/50 - D Loss: 0.1674, G Loss: 0.5178\n",
            "[LSGAN] Epoch 48/50 - D Loss: 0.2017, G Loss: 0.3846\n",
            "[LSGAN] Epoch 49/50 - D Loss: 0.1469, G Loss: 0.5923\n",
            "[LSGAN] Epoch 50/50 - D Loss: 0.1380, G Loss: 0.6385\n",
            "✅ Saved LSGAN model to models/LSGAN_generator.pth\n",
            "\n",
            "🚀 Training WGAN...\n",
            "[WGAN] Epoch 1/50 - D Loss: -0.0934, G Loss: 0.0261\n",
            "[WGAN] Epoch 2/50 - D Loss: -0.1277, G Loss: 0.2160\n",
            "[WGAN] Epoch 3/50 - D Loss: -0.4960, G Loss: 0.2127\n",
            "[WGAN] Epoch 4/50 - D Loss: 0.0749, G Loss: 0.0211\n",
            "[WGAN] Epoch 5/50 - D Loss: -0.0283, G Loss: -0.0005\n",
            "[WGAN] Epoch 6/50 - D Loss: -0.0411, G Loss: -0.0996\n",
            "[WGAN] Epoch 7/50 - D Loss: -0.0242, G Loss: 0.2380\n",
            "[WGAN] Epoch 8/50 - D Loss: -0.0525, G Loss: 0.0223\n",
            "[WGAN] Epoch 9/50 - D Loss: -0.0939, G Loss: -0.1243\n",
            "[WGAN] Epoch 10/50 - D Loss: -0.0429, G Loss: 0.1267\n",
            "[WGAN] Epoch 11/50 - D Loss: -0.0130, G Loss: -0.1342\n",
            "[WGAN] Epoch 12/50 - D Loss: -0.0535, G Loss: 0.1121\n",
            "[WGAN] Epoch 13/50 - D Loss: -0.0752, G Loss: -0.0938\n",
            "[WGAN] Epoch 14/50 - D Loss: -0.0480, G Loss: 0.1021\n",
            "[WGAN] Epoch 15/50 - D Loss: -0.0657, G Loss: 0.0680\n",
            "[WGAN] Epoch 16/50 - D Loss: -0.0566, G Loss: 0.0171\n",
            "[WGAN] Epoch 17/50 - D Loss: -0.0283, G Loss: 0.0591\n",
            "[WGAN] Epoch 18/50 - D Loss: -0.0358, G Loss: -0.0081\n",
            "[WGAN] Epoch 19/50 - D Loss: -0.0160, G Loss: -0.0215\n",
            "[WGAN] Epoch 20/50 - D Loss: -0.0204, G Loss: 0.0629\n",
            "[WGAN] Epoch 21/50 - D Loss: -0.0152, G Loss: -0.0292\n",
            "[WGAN] Epoch 22/50 - D Loss: -0.1071, G Loss: 0.0934\n",
            "[WGAN] Epoch 23/50 - D Loss: -0.0261, G Loss: -0.0271\n",
            "[WGAN] Epoch 24/50 - D Loss: -0.0471, G Loss: 0.0422\n",
            "[WGAN] Epoch 25/50 - D Loss: -0.0227, G Loss: 0.0803\n",
            "[WGAN] Epoch 26/50 - D Loss: -0.0272, G Loss: -0.0511\n",
            "[WGAN] Epoch 27/50 - D Loss: 0.0358, G Loss: -0.1085\n",
            "[WGAN] Epoch 28/50 - D Loss: -0.0887, G Loss: -0.1254\n",
            "[WGAN] Epoch 29/50 - D Loss: -0.0386, G Loss: 0.0215\n",
            "[WGAN] Epoch 30/50 - D Loss: 0.0669, G Loss: -0.0621\n",
            "[WGAN] Epoch 31/50 - D Loss: -0.0784, G Loss: 0.0121\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create directories for saving models\n",
        "MODEL_DIR = \"models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Check for CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the GAN training function\n",
        "def train_gan(gan_type=\"LSGAN\", epochs=50):\n",
        "    print(f\"\\n🚀 Training {gan_type}...\")\n",
        "\n",
        "    # Initialize generator and discriminator\n",
        "    generator = Generator().to(device)\n",
        "    discriminator = Discriminator().to(device)\n",
        "\n",
        "    if gan_type == \"LSGAN\":\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    elif gan_type == \"WGAN\":\n",
        "        optimizer_G = optim.RMSprop(generator.parameters(), lr=0.00005)\n",
        "        optimizer_D = optim.RMSprop(discriminator.parameters(), lr=0.00005)\n",
        "\n",
        "    elif gan_type == \"WGAN-GP\":\n",
        "        optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
        "        optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown GAN type: {gan_type}\")\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        for i, (real_imgs, _) in enumerate(dataloader):\n",
        "            real_imgs = real_imgs.to(device)\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Generate fake images\n",
        "            z = torch.randn(real_imgs.size(0), 100, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            real_validity = discriminator(real_imgs)\n",
        "            fake_validity = discriminator(fake_imgs.detach())\n",
        "\n",
        "            if gan_type == \"LSGAN\":\n",
        "                real_loss = criterion(real_validity, torch.ones_like(real_validity))\n",
        "                fake_loss = criterion(fake_validity, torch.zeros_like(fake_validity))\n",
        "                d_loss = (real_loss + fake_loss) / 2\n",
        "            elif gan_type == \"WGAN\":\n",
        "                d_loss = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
        "                for p in discriminator.parameters():\n",
        "                    p.data.clamp_(-0.01, 0.01)\n",
        "            elif gan_type == \"WGAN-GP\":\n",
        "                gradient_penalty = compute_gradient_penalty(discriminator, real_imgs, fake_imgs)\n",
        "                d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + 10 * gradient_penalty\n",
        "\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "            if i % 5 == 0:\n",
        "                optimizer_G.zero_grad()\n",
        "                fake_validity = discriminator(fake_imgs)\n",
        "                g_loss = -torch.mean(fake_validity) if gan_type != \"LSGAN\" else criterion(fake_validity, torch.ones_like(fake_validity))\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "        print(f\"[{gan_type}] Epoch {epoch+1}/{epochs} - D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # ✅ Save the trained generator\n",
        "    model_path = os.path.join(MODEL_DIR, f\"{gan_type}_generator.pth\")\n",
        "    torch.save(generator.state_dict(), model_path)\n",
        "    print(f\"✅ Saved {gan_type} model to {model_path}\")\n",
        "\n",
        "    return generator  # Return the trained generator\n",
        "\n",
        "# Train and save all GANs\n",
        "gan_types = [\"LSGAN\", \"WGAN\", \"WGAN-GP\"]\n",
        "trained_generators = {gan_type: train_gan(gan_type, epochs=50) for gan_type in gan_types}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaNpOVLtYReG",
        "outputId": "5cbff8c6-c13a-4084-862a-0232311a0845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1/50] [D loss: -7.4943] [G loss: 4.8444]\n",
            "[Epoch 2/50] [D loss: -6.8537] [G loss: 6.2654]\n",
            "[Epoch 3/50] [D loss: -5.6110] [G loss: 2.6428]\n",
            "[Epoch 4/50] [D loss: -4.5170] [G loss: -0.0686]\n",
            "[Epoch 5/50] [D loss: -5.2459] [G loss: 0.3764]\n",
            "[Epoch 6/50] [D loss: -4.1785] [G loss: 0.8363]\n",
            "[Epoch 7/50] [D loss: -4.4183] [G loss: 0.1295]\n",
            "[Epoch 8/50] [D loss: -4.0026] [G loss: -0.2366]\n",
            "[Epoch 9/50] [D loss: -3.4754] [G loss: 0.9665]\n",
            "[Epoch 10/50] [D loss: -2.8785] [G loss: 1.9728]\n",
            "[Epoch 11/50] [D loss: -2.4127] [G loss: 1.5790]\n",
            "[Epoch 12/50] [D loss: -3.3286] [G loss: -0.2191]\n",
            "[Epoch 13/50] [D loss: -3.1321] [G loss: 0.6837]\n",
            "[Epoch 14/50] [D loss: -2.8933] [G loss: -0.3563]\n",
            "[Epoch 15/50] [D loss: -2.4938] [G loss: -0.0013]\n",
            "[Epoch 16/50] [D loss: -3.0848] [G loss: 1.1548]\n",
            "[Epoch 17/50] [D loss: -2.0192] [G loss: -0.8589]\n",
            "[Epoch 18/50] [D loss: -3.0897] [G loss: 1.0825]\n",
            "[Epoch 19/50] [D loss: -2.6241] [G loss: -0.8277]\n",
            "[Epoch 20/50] [D loss: -2.3579] [G loss: -2.4548]\n",
            "[Epoch 21/50] [D loss: -2.5957] [G loss: -1.3716]\n",
            "[Epoch 22/50] [D loss: -1.6695] [G loss: -1.0614]\n",
            "[Epoch 23/50] [D loss: -2.3679] [G loss: 1.0740]\n",
            "[Epoch 24/50] [D loss: -1.8480] [G loss: 0.2024]\n",
            "[Epoch 25/50] [D loss: -1.8436] [G loss: 1.8595]\n",
            "[Epoch 26/50] [D loss: -2.4108] [G loss: 0.5443]\n",
            "[Epoch 27/50] [D loss: -2.1770] [G loss: 0.1531]\n",
            "[Epoch 28/50] [D loss: -2.0575] [G loss: 0.9445]\n",
            "[Epoch 29/50] [D loss: -1.7439] [G loss: 0.2899]\n",
            "[Epoch 30/50] [D loss: -2.4682] [G loss: 3.5401]\n",
            "[Epoch 31/50] [D loss: -2.6389] [G loss: -3.2022]\n",
            "[Epoch 32/50] [D loss: -1.9743] [G loss: -0.8908]\n",
            "[Epoch 33/50] [D loss: -2.3319] [G loss: -1.6106]\n",
            "[Epoch 34/50] [D loss: -2.2266] [G loss: -1.7731]\n",
            "[Epoch 35/50] [D loss: -1.9476] [G loss: 1.5834]\n",
            "[Epoch 36/50] [D loss: -1.1406] [G loss: -1.5617]\n",
            "[Epoch 37/50] [D loss: -1.7838] [G loss: 0.1126]\n",
            "[Epoch 38/50] [D loss: -1.1447] [G loss: -0.0633]\n",
            "[Epoch 39/50] [D loss: -2.7459] [G loss: -1.6207]\n",
            "[Epoch 40/50] [D loss: -1.5004] [G loss: -0.4585]\n",
            "[Epoch 41/50] [D loss: -1.5378] [G loss: -0.7626]\n",
            "[Epoch 42/50] [D loss: -1.0101] [G loss: -2.4947]\n",
            "[Epoch 43/50] [D loss: -1.9111] [G loss: -1.5509]\n",
            "[Epoch 44/50] [D loss: -2.0654] [G loss: 0.3138]\n",
            "[Epoch 45/50] [D loss: -2.1542] [G loss: -0.0233]\n",
            "[Epoch 46/50] [D loss: -0.9773] [G loss: -1.0501]\n",
            "[Epoch 47/50] [D loss: -2.1549] [G loss: 1.7222]\n",
            "[Epoch 48/50] [D loss: -1.9503] [G loss: 1.3895]\n",
            "[Epoch 49/50] [D loss: -1.9353] [G loss: -0.9654]\n",
            "[Epoch 50/50] [D loss: -0.8657] [G loss: -5.5748]\n",
            "Training complete!\n",
            "[Epoch 1/50] [D loss: -6.6088] [G loss: 7.2083]\n",
            "[Epoch 2/50] [D loss: -5.7659] [G loss: 4.6594]\n",
            "[Epoch 3/50] [D loss: -4.4037] [G loss: 1.7597]\n",
            "[Epoch 4/50] [D loss: -4.4390] [G loss: -0.7713]\n",
            "[Epoch 5/50] [D loss: -4.5463] [G loss: 0.7080]\n",
            "[Epoch 6/50] [D loss: -3.5704] [G loss: 1.1989]\n",
            "[Epoch 7/50] [D loss: -3.1985] [G loss: 0.8609]\n",
            "[Epoch 8/50] [D loss: -3.7274] [G loss: 0.7439]\n",
            "[Epoch 9/50] [D loss: -4.1991] [G loss: 1.3254]\n",
            "[Epoch 10/50] [D loss: -3.0263] [G loss: 0.0433]\n",
            "[Epoch 11/50] [D loss: -3.1108] [G loss: 1.1850]\n",
            "[Epoch 12/50] [D loss: -2.6847] [G loss: 1.1058]\n",
            "[Epoch 13/50] [D loss: -2.5669] [G loss: 0.1475]\n",
            "[Epoch 14/50] [D loss: -2.1241] [G loss: -0.4838]\n",
            "[Epoch 15/50] [D loss: -3.6055] [G loss: 0.1598]\n",
            "[Epoch 16/50] [D loss: -2.3044] [G loss: 0.8587]\n",
            "[Epoch 17/50] [D loss: -2.6578] [G loss: 1.2505]\n",
            "[Epoch 18/50] [D loss: -3.3498] [G loss: -0.7013]\n",
            "[Epoch 19/50] [D loss: -2.6071] [G loss: -1.8428]\n",
            "[Epoch 20/50] [D loss: -2.8706] [G loss: 0.1916]\n",
            "[Epoch 21/50] [D loss: -2.1425] [G loss: -1.5954]\n",
            "[Epoch 22/50] [D loss: -2.4961] [G loss: -0.6033]\n",
            "[Epoch 23/50] [D loss: -3.1387] [G loss: 0.3621]\n",
            "[Epoch 24/50] [D loss: -1.0624] [G loss: -0.2860]\n",
            "[Epoch 25/50] [D loss: -1.1220] [G loss: -1.5761]\n",
            "[Epoch 26/50] [D loss: -1.7163] [G loss: -0.5425]\n",
            "[Epoch 27/50] [D loss: -2.0531] [G loss: -0.7808]\n",
            "[Epoch 28/50] [D loss: -2.3523] [G loss: 0.7216]\n",
            "[Epoch 29/50] [D loss: -2.4343] [G loss: -0.4962]\n",
            "[Epoch 30/50] [D loss: -1.6629] [G loss: 1.1937]\n",
            "[Epoch 31/50] [D loss: -2.2322] [G loss: -0.2634]\n",
            "[Epoch 32/50] [D loss: -1.2777] [G loss: -1.3639]\n",
            "[Epoch 33/50] [D loss: -1.3848] [G loss: 0.2495]\n",
            "[Epoch 34/50] [D loss: -0.9290] [G loss: -2.2473]\n",
            "[Epoch 35/50] [D loss: -1.8308] [G loss: -1.5681]\n",
            "[Epoch 36/50] [D loss: -2.7890] [G loss: 0.1290]\n",
            "[Epoch 37/50] [D loss: -2.5697] [G loss: 0.4873]\n",
            "[Epoch 38/50] [D loss: -2.0697] [G loss: 0.4413]\n",
            "[Epoch 39/50] [D loss: -1.6564] [G loss: -0.5140]\n",
            "[Epoch 40/50] [D loss: -1.5153] [G loss: 2.6349]\n",
            "[Epoch 41/50] [D loss: -0.8332] [G loss: 0.5083]\n",
            "[Epoch 42/50] [D loss: -1.9366] [G loss: 3.4512]\n",
            "[Epoch 43/50] [D loss: -2.0904] [G loss: 1.2946]\n",
            "[Epoch 44/50] [D loss: -2.4426] [G loss: 1.4136]\n",
            "[Epoch 45/50] [D loss: -1.1351] [G loss: 0.0015]\n",
            "[Epoch 46/50] [D loss: -2.5080] [G loss: -0.1023]\n",
            "[Epoch 47/50] [D loss: -1.2072] [G loss: -0.7015]\n",
            "[Epoch 48/50] [D loss: -2.0331] [G loss: -0.7784]\n",
            "[Epoch 49/50] [D loss: -1.5658] [G loss: 2.5454]\n",
            "[Epoch 50/50] [D loss: -0.6628] [G loss: -2.3331]\n",
            "Training complete!\n",
            "[Epoch 1/50] [D loss: -7.3742] [G loss: 4.7088]\n",
            "[Epoch 2/50] [D loss: -6.4321] [G loss: 4.1888]\n",
            "[Epoch 3/50] [D loss: -5.3923] [G loss: 0.2652]\n",
            "[Epoch 4/50] [D loss: -4.7290] [G loss: 0.2557]\n",
            "[Epoch 5/50] [D loss: -4.1916] [G loss: 0.7987]\n",
            "[Epoch 6/50] [D loss: -4.0661] [G loss: 0.0013]\n",
            "[Epoch 7/50] [D loss: -4.3505] [G loss: 0.4647]\n",
            "[Epoch 8/50] [D loss: -4.1794] [G loss: 1.0172]\n",
            "[Epoch 9/50] [D loss: -3.0049] [G loss: -0.5654]\n",
            "[Epoch 10/50] [D loss: -3.0605] [G loss: 1.2551]\n",
            "[Epoch 11/50] [D loss: -3.1652] [G loss: 0.0878]\n",
            "[Epoch 12/50] [D loss: -3.2215] [G loss: 0.2595]\n",
            "[Epoch 13/50] [D loss: -2.7332] [G loss: 1.4749]\n",
            "[Epoch 14/50] [D loss: -2.3226] [G loss: -0.7934]\n",
            "[Epoch 15/50] [D loss: -2.0645] [G loss: 0.5145]\n",
            "[Epoch 16/50] [D loss: -2.5690] [G loss: -1.1608]\n",
            "[Epoch 17/50] [D loss: -3.6745] [G loss: -1.8559]\n",
            "[Epoch 18/50] [D loss: -2.6947] [G loss: -0.2810]\n",
            "[Epoch 19/50] [D loss: -2.2279] [G loss: -2.5365]\n",
            "[Epoch 20/50] [D loss: -2.3144] [G loss: -0.3595]\n",
            "[Epoch 21/50] [D loss: -2.3641] [G loss: 0.2313]\n",
            "[Epoch 22/50] [D loss: -2.3021] [G loss: -0.0005]\n",
            "[Epoch 23/50] [D loss: -3.0876] [G loss: 0.7559]\n",
            "[Epoch 24/50] [D loss: -2.9922] [G loss: 1.9836]\n",
            "[Epoch 25/50] [D loss: -2.0928] [G loss: 0.4872]\n",
            "[Epoch 26/50] [D loss: -2.1584] [G loss: -0.6359]\n",
            "[Epoch 27/50] [D loss: -1.8132] [G loss: -1.2488]\n",
            "[Epoch 28/50] [D loss: -2.1611] [G loss: 2.3921]\n",
            "[Epoch 29/50] [D loss: -1.0932] [G loss: 0.3804]\n",
            "[Epoch 30/50] [D loss: -2.4280] [G loss: 0.2700]\n",
            "[Epoch 31/50] [D loss: -2.6065] [G loss: 2.9290]\n",
            "[Epoch 32/50] [D loss: -2.3399] [G loss: 0.9537]\n",
            "[Epoch 33/50] [D loss: -2.9540] [G loss: -0.3230]\n",
            "[Epoch 34/50] [D loss: -1.9087] [G loss: 0.9248]\n",
            "[Epoch 35/50] [D loss: -1.5645] [G loss: 0.3728]\n",
            "[Epoch 36/50] [D loss: -1.3475] [G loss: 1.3878]\n",
            "[Epoch 37/50] [D loss: -2.9087] [G loss: -0.1791]\n",
            "[Epoch 38/50] [D loss: -1.6864] [G loss: -2.5875]\n",
            "[Epoch 39/50] [D loss: -2.8428] [G loss: -2.2964]\n",
            "[Epoch 40/50] [D loss: -2.2276] [G loss: -0.2752]\n",
            "[Epoch 41/50] [D loss: 0.7885] [G loss: -3.0448]\n",
            "[Epoch 42/50] [D loss: -1.0802] [G loss: -0.6555]\n",
            "[Epoch 43/50] [D loss: -0.9184] [G loss: -1.7139]\n",
            "[Epoch 44/50] [D loss: -2.2471] [G loss: 0.0612]\n",
            "[Epoch 45/50] [D loss: -1.3672] [G loss: -2.0073]\n",
            "[Epoch 46/50] [D loss: -2.4082] [G loss: 2.2910]\n",
            "[Epoch 47/50] [D loss: -1.9023] [G loss: -0.6333]\n",
            "[Epoch 48/50] [D loss: -1.2399] [G loss: 2.2223]\n",
            "[Epoch 49/50] [D loss: -1.6848] [G loss: -0.0199]\n",
            "[Epoch 50/50] [D loss: -1.8735] [G loss: 0.7375]\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Train all GANs\n",
        "train_gan(\"WGAN-GP\", epochs=50)\n",
        "train_gan(\"LSGAN\", epochs=50)\n",
        "train_gan(\"WGAN\", epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKedSXCVgrqH"
      },
      "outputs": [],
      "source": [
        "#updated code for gans training saving the models and evaluationg the models\n",
        "import os\n",
        "import torch\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "\n",
        "# Directory to save models and generated images\n",
        "MODEL_DIR = \"models\"\n",
        "IMAGE_DIR = \"generated\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "# Generate images from a trained model\n",
        "def generate_images(generator, num_samples=500):\n",
        "    z = torch.randn(num_samples, 100, device=device)\n",
        "    fake_imgs = generator(z)\n",
        "    return fake_imgs\n",
        "\n",
        "# Compute Inception Score\n",
        "def compute_inception_score(fake_imgs):\n",
        "    is_metric = InceptionScore(feature=2048).to(device)\n",
        "    score = is_metric(fake_imgs)\n",
        "    return score.item()\n",
        "\n",
        "# Compute FID\n",
        "def compute_fid(real_imgs, fake_imgs):\n",
        "    fid_metric = FrechetInceptionDistance(feature=2048).to(device)\n",
        "\n",
        "    fid_metric.update(real_imgs, real=True)\n",
        "    fid_metric.update(fake_imgs, real=False)\n",
        "\n",
        "    return fid_metric.compute().item()\n",
        "\n",
        "# Visual Inspection\n",
        "def visualize_images(fake_imgs, title=\"Generated Images\", save_path=None):\n",
        "    fake_imgs = fake_imgs[:16]  # Show 16 images\n",
        "    grid = vutils.make_grid(fake_imgs, normalize=True).cpu().permute(1, 2, 0)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(grid)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Saved image: {save_path}\")\n",
        "\n",
        "# Train all GANs and store their models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gan_types = [\"LSGAN\", \"WGAN\", \"WGAN-GP\"]\n",
        "trained_generators = {}\n",
        "\n",
        "for gan_type in gan_types:\n",
        "    model_path = os.path.join(MODEL_DIR, f\"{gan_type}_generator.pth\")\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"\\nSkipping training for {gan_type}, model already exists.\")\n",
        "        continue  # Skip training if model is already saved\n",
        "\n",
        "    print(f\"\\nTraining {gan_type}...\")\n",
        "    generator = train_gan(gan_type, epochs=50)  # ✅ Train model\n",
        "    trained_generators[gan_type] = generator  # ✅ Store trained generator\n",
        "\n",
        "    # ✅ Save model to disk\n",
        "    torch.save(generator.state_dict(), model_path)\n",
        "    print(f\"Saved {gan_type} model to {model_path}\")\n",
        "\n",
        "# Load trained models for evaluation\n",
        "results = {}\n",
        "\n",
        "for gan_type in gan_types:\n",
        "    model_path = os.path.join(MODEL_DIR, f\"{gan_type}_generator.pth\")\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Error: Model {model_path} not found! Skipping evaluation.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nLoading trained {gan_type} model for evaluation...\")\n",
        "\n",
        "    generator = Generator().to(device)  # Initialize generator\n",
        "    generator.load_state_dict(torch.load(model_path))  # Load saved model\n",
        "    generator.eval()\n",
        "\n",
        "    fake_images = generate_images(generator, num_samples=500)\n",
        "\n",
        "    # Compute IS\n",
        "    inception_score = compute_inception_score(fake_images)\n",
        "\n",
        "    # Compute FID\n",
        "    fid_score = compute_fid(real_images, fake_images)\n",
        "\n",
        "    # Visual Inspection\n",
        "    image_path = os.path.join(IMAGE_DIR, f\"{gan_type}_generated.png\")\n",
        "    visualize_images(fake_images, title=f\"{gan_type} Generated Images\", save_path=image_path)\n",
        "\n",
        "    # Store results\n",
        "    results[gan_type] = {\"Inception Score\": inception_score, \"FID Score\": fid_score}\n",
        "\n",
        "# Print final evaluation results\n",
        "print(\"\\n===== GAN Performance Comparison =====\")\n",
        "for gan, scores in results.items():\n",
        "    print(f\"{gan}: Inception Score = {scores['Inception Score']:.4f}, FID Score = {scores['FID Score']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vt5ymcESXKgB",
        "outputId": "69a4890b-8fb6-4fe9-deaa-8fb33fd6261e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LSGAN...\n",
            "[Epoch 1/50] [D loss: -7.3094] [G loss: 6.9294]\n",
            "[Epoch 2/50] [D loss: -6.8139] [G loss: 5.7999]\n",
            "[Epoch 3/50] [D loss: -7.1039] [G loss: 4.1957]\n",
            "[Epoch 4/50] [D loss: -5.0366] [G loss: 1.6582]\n",
            "[Epoch 5/50] [D loss: -4.3761] [G loss: 1.5712]\n",
            "[Epoch 6/50] [D loss: -4.0551] [G loss: 0.7777]\n",
            "[Epoch 7/50] [D loss: -3.5168] [G loss: -0.0991]\n",
            "[Epoch 8/50] [D loss: -3.7128] [G loss: 0.7489]\n",
            "[Epoch 9/50] [D loss: -2.9072] [G loss: 1.1476]\n",
            "[Epoch 10/50] [D loss: -3.5268] [G loss: 0.1479]\n",
            "[Epoch 11/50] [D loss: -3.3256] [G loss: 0.5671]\n",
            "[Epoch 12/50] [D loss: -2.2581] [G loss: 0.6660]\n",
            "[Epoch 13/50] [D loss: -2.8166] [G loss: 0.3038]\n",
            "[Epoch 14/50] [D loss: -4.0532] [G loss: -0.6886]\n",
            "[Epoch 15/50] [D loss: -2.5041] [G loss: -0.1326]\n",
            "[Epoch 16/50] [D loss: -1.8693] [G loss: 1.4195]\n",
            "[Epoch 17/50] [D loss: -2.6371] [G loss: 1.0665]\n",
            "[Epoch 18/50] [D loss: -2.4649] [G loss: 1.4027]\n",
            "[Epoch 19/50] [D loss: -1.5763] [G loss: -0.5785]\n",
            "[Epoch 20/50] [D loss: -2.5599] [G loss: 0.0173]\n",
            "[Epoch 21/50] [D loss: -2.2062] [G loss: -0.2005]\n",
            "[Epoch 22/50] [D loss: -2.2730] [G loss: 1.0295]\n",
            "[Epoch 23/50] [D loss: -1.8090] [G loss: -0.3940]\n",
            "[Epoch 24/50] [D loss: -2.2900] [G loss: -2.1433]\n",
            "[Epoch 25/50] [D loss: -2.8542] [G loss: 1.1167]\n",
            "[Epoch 26/50] [D loss: -2.8301] [G loss: 1.1116]\n",
            "[Epoch 27/50] [D loss: -2.0330] [G loss: 0.6056]\n",
            "[Epoch 28/50] [D loss: -1.6173] [G loss: -0.1779]\n",
            "[Epoch 29/50] [D loss: -2.7980] [G loss: -0.5728]\n",
            "[Epoch 30/50] [D loss: -2.9883] [G loss: 0.0917]\n",
            "[Epoch 31/50] [D loss: -2.1078] [G loss: 0.0335]\n",
            "[Epoch 32/50] [D loss: -1.7681] [G loss: -0.8102]\n",
            "[Epoch 33/50] [D loss: -1.9511] [G loss: 1.0225]\n",
            "[Epoch 34/50] [D loss: -1.8200] [G loss: -3.3826]\n",
            "[Epoch 35/50] [D loss: -1.4729] [G loss: 0.6006]\n",
            "[Epoch 36/50] [D loss: -2.6936] [G loss: 2.2896]\n",
            "[Epoch 37/50] [D loss: -0.9689] [G loss: 0.8349]\n",
            "[Epoch 38/50] [D loss: -1.3432] [G loss: -0.6750]\n",
            "[Epoch 39/50] [D loss: -0.9781] [G loss: 0.1772]\n",
            "[Epoch 40/50] [D loss: -1.3421] [G loss: -0.9690]\n",
            "[Epoch 41/50] [D loss: -1.3779] [G loss: 0.1088]\n",
            "[Epoch 42/50] [D loss: -1.3854] [G loss: 0.8206]\n",
            "[Epoch 43/50] [D loss: -2.5482] [G loss: 1.2039]\n",
            "[Epoch 44/50] [D loss: -1.8480] [G loss: -2.8045]\n",
            "[Epoch 45/50] [D loss: -1.7003] [G loss: -0.8440]\n",
            "[Epoch 46/50] [D loss: -3.3722] [G loss: 0.5782]\n",
            "[Epoch 47/50] [D loss: -1.4205] [G loss: -1.6286]\n",
            "[Epoch 48/50] [D loss: -1.9662] [G loss: -1.9524]\n",
            "[Epoch 49/50] [D loss: -1.8543] [G loss: -0.9839]\n",
            "[Epoch 50/50] [D loss: -2.0618] [G loss: 1.0428]\n",
            "Training complete!\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'state_dict'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-604468d8186d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# ✅ Save model to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved {gan_type} model to {model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'state_dict'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "MODEL_DIR = \"models\"\n",
        "IMAGE_DIR = \"generated\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gan_types = [\"LSGAN\", \"WGAN\", \"WGAN-GP\"]\n",
        "trained_generators = {}\n",
        "for gan_type in gan_types:\n",
        "    model_path = os.path.join(MODEL_DIR, f\"{gan_type}_generator.pth\")\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"\\nSkipping training for {gan_type}, model already exists.\")\n",
        "        continue  # Skip training if model is already saved\n",
        "\n",
        "    print(f\"\\nTraining {gan_type}...\")\n",
        "    generator = train_gan(gan_type, epochs=50)  # ✅ Train model\n",
        "    trained_generators[gan_type] = generator  # ✅ Store trained generator\n",
        "\n",
        "    # ✅ Save model to disk\n",
        "    torch.save(generator.state_dict(), model_path)\n",
        "    print(f\"Saved {gan_type} model to {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwRLuKZ3hpCy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "\n",
        "# TensorBoard Setup\n",
        "LOG_DIR = \"runs/gan_evaluation\"\n",
        "writer = SummaryWriter(LOG_DIR)\n",
        "\n",
        "# Generate images from a trained model\n",
        "def generate_images(generator, num_samples=500):\n",
        "    z = torch.randn(num_samples, 100, device=device)\n",
        "    fake_imgs = generator(z)\n",
        "    return fake_imgs\n",
        "\n",
        "# Compute Inception Score\n",
        "def compute_inception_score(fake_imgs):\n",
        "    is_metric = InceptionScore(feature=2048).to(device)\n",
        "    score = is_metric(fake_imgs)\n",
        "    return score.item()\n",
        "\n",
        "# Compute FID\n",
        "def compute_fid(real_imgs, fake_imgs):\n",
        "    fid_metric = FrechetInceptionDistance(feature=2048).to(device)\n",
        "\n",
        "    fid_metric.update(real_imgs, real=True)\n",
        "    fid_metric.update(fake_imgs, real=False)\n",
        "\n",
        "    return fid_metric.compute().item()\n",
        "\n",
        "# Log Images to TensorBoard\n",
        "def log_images(fake_imgs, step, gan_type):\n",
        "    fake_imgs = fake_imgs[:16]  # Select 16 images\n",
        "    grid = vutils.make_grid(fake_imgs, normalize=True)\n",
        "\n",
        "    writer.add_image(f\"Generated Images/{gan_type}\", grid, step)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for step, gan_type in enumerate(gan_types):\n",
        "    model_path = os.path.join(MODEL_DIR, f\"{gan_type}_generator.pth\")\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Error: Model {model_path} not found! Skipping evaluation.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nLoading trained {gan_type} model for evaluation...\")\n",
        "\n",
        "    generator = Generator().to(device)  # Initialize generator\n",
        "    generator.load_state_dict(torch.load(model_path))  # Load saved model\n",
        "    generator.eval()\n",
        "\n",
        "    fake_images = generate_images(generator, num_samples=500)\n",
        "\n",
        "    # Compute IS\n",
        "    inception_score = compute_inception_score(fake_images)\n",
        "\n",
        "    # Compute FID\n",
        "    fid_score = compute_fid(real_images, fake_images)\n",
        "\n",
        "    # Log Images to TensorBoard\n",
        "    log_images(fake_images, step, gan_type)\n",
        "\n",
        "    # Log Scores to TensorBoard\n",
        "    writer.add_scalar(f\"{gan_type}/Inception Score\", inception_score, step)\n",
        "    writer.add_scalar(f\"{gan_type}/FID Score\", fid_score, step)\n",
        "\n",
        "    # Store results\n",
        "    results[gan_type] = {\"Inception Score\": inception_score, \"FID Score\": fid_score}\n",
        "\n",
        "# Print final evaluation results\n",
        "print(\"\\n===== GAN Performance Comparison =====\")\n",
        "for gan, scores in results.items():\n",
        "    print(f\"{gan}: Inception Score = {scores['Inception Score']:.4f}, FID Score = {scores['FID Score']:.4f}\")\n",
        "\n",
        "# Close TensorBoard Writer\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_DXcxo3h87B"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs/gan_evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MATJqBLbp8Sq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "\n",
        "# TensorBoard Setup\n",
        "LOG_DIR = \"runs/gan_evaluation\"\n",
        "writer = SummaryWriter(LOG_DIR)\n",
        "\n",
        "# Directory to save models and generated images\n",
        "MODEL_DIR = \"models\"\n",
        "IMAGE_DIR = \"generated\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "# Generate images from a trained model\n",
        "def generate_images(generator, num_samples=500):\n",
        "    z = torch.randn(num_samples, 100, device=device)\n",
        "    fake_imgs = generator(z)\n",
        "    return fake_imgs\n",
        "\n",
        "# Compute Inception Score\n",
        "def compute_inception_score(fake_imgs):\n",
        "    is_metric = InceptionScore(feature=2048).to(device)\n",
        "    score = is_metric(fake_imgs)\n",
        "    return score.item()\n",
        "\n",
        "# Compute FID\n",
        "def compute_fid(real_imgs, fake_imgs):\n",
        "    fid_metric = FrechetInceptionDistance(feature=2048).to(device)\n",
        "\n",
        "    fid_metric.update(real_imgs, real=True)\n",
        "    fid_metric.update(fake_imgs, real=False)\n",
        "\n",
        "    return fid_metric.compute().item()\n",
        "\n",
        "# Log Images to TensorBoard\n",
        "def log_images(fake_imgs, step, gan_type):\n",
        "    fake_imgs = fake_imgs[:16]  # Select 16 images\n",
        "    grid = vutils.make_grid(fake_imgs, normalize=True)\n",
        "\n",
        "    writer.add_image(f\"Generated Images/{gan_type}\", grid, step)\n",
        "\n",
        "# Train all GANs and store their models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gan_types = [\"LSGAN\", \"WGAN\", \"WGAN-GP\"]\n",
        "trained_generators = {}\n",
        "\n",
        "for gan_type in gan_types:\n",
        "    model_path = os.path.join(MODEL_DIR, f\"{gan_type}_generator.pth\")\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"\\nSkipping training for {gan_type}, model already exists.\")\n",
        "        continue  # Skip training if model is already saved\n",
        "\n",
        "    print(f\"\\nTraining {gan_type}...\")\n",
        "    generator = train_gan(gan_type, epochs=50)  # ✅ Train model\n",
        "    trained_generators[gan_type] = generator  # ✅ Store trained generator\n",
        "\n",
        "    # ✅ Save model to disk\n",
        "    torch.save(generator.state_dict(), model_path)\n",
        "    print(f\"Saved {gan_type} model to {model_path}\")\n",
        "\n",
        "# Load trained models for evaluation\n",
        "results = {}\n",
        "\n",
        "for step, gan_type in enumerate(gan_types):\n",
        "    model_path = os.path.join(MODEL_DIR, f\"{gan_type}_generator.pth\")\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Error: Model {model_path} not found! Skipping evaluation.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nLoading trained {gan_type} model for evaluation...\")\n",
        "\n",
        "    generator = Generator().to(device)  # Initialize generator\n",
        "    generator.load_state_dict(torch.load(model_path))  # Load saved model\n",
        "    generator.eval()\n",
        "\n",
        "    fake_images = generate_images(generator, num_samples=500)\n",
        "\n",
        "    # Compute IS\n",
        "    inception_score = compute_inception_score(fake_images)\n",
        "\n",
        "    # Compute FID\n",
        "    fid_score = compute_fid(real_images, fake_images)\n",
        "\n",
        "    # Log Images to TensorBoard\n",
        "    log_images(fake_images, step, gan_type)\n",
        "\n",
        "    # Log Scores to TensorBoard\n",
        "    writer.add_scalar(f\"{gan_type}/Inception Score\", inception_score, step)\n",
        "    writer.add_scalar(f\"{gan_type}/FID Score\", fid_score, step)\n",
        "\n",
        "    # Store results\n",
        "    results[gan_type] = {\"Inception Score\": inception_score, \"FID Score\": fid_score}\n",
        "\n",
        "# Print final evaluation results\n",
        "print(\"\\n===== GAN Performance Comparison =====\")\n",
        "for gan, scores in results.items():\n",
        "    print(f\"{gan}: Inception Score = {scores['Inception Score']:.4f}, FID Score = {scores['FID Score']:.4f}\")\n",
        "\n",
        "# Close TensorBoard Writer\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-A-JesSMay_g"
      },
      "outputs": [],
      "source": [
        "# Function to Display Generated Images\n",
        "def show_generated_images():\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    for i, (gan_name, _) in enumerate(gan_models.items()):\n",
        "        img = plt.imread(f\"generated/{gan_name}_samples.png\")\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].axis(\"off\")\n",
        "        axes[i].set_title(gan_name)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vfEUHiBha1OX"
      },
      "outputs": [],
      "source": [
        "# Show Sample Images from Each GAN\n",
        "show_generated_images()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}